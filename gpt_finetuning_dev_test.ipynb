{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac03766-ac48-4e03-b38d-55df5e36c518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:57:56.562441Z",
     "start_time": "2021-09-27T06:57:56.550442Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from setproctitle import setproctitle\n",
    "setproctitle(\"Hodong_GPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f54acd7-f203-4b80-939c-2ade74eacab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:58:00.070300Z",
     "start_time": "2021-09-27T06:57:56.564469Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformer.data.generator_dataset import GptDatasetFromDir, GeneratorDataLoader\n",
    "from transformer.tokenizer.utils import make_custom_tokenizer_from_pretrained, load_tokenizer_from_pretrained\n",
    "from transformer.models.interface import TrainHistory\n",
    "from transformer.models.gpt import Gpt2\n",
    "from transformer.models.utils import load_state_dict, get_score_json\n",
    "from transformer.utils.common import set_device, convert_to_tensor, init_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbef43a-805e-4beb-82ee-3209b3395b62",
   "metadata": {},
   "source": [
    "### Set WorkingDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb1dcdd-f28a-42ad-bd54-7d853bc73a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:58:00.085855Z",
     "start_time": "2021-09-27T06:58:00.073257Z"
    }
   },
   "outputs": [],
   "source": [
    "# # AIBUD_DEV\n",
    "# dataset_dir = \"/Users/aibud_dev/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# Korea_Server\n",
    "dataset_dir = \"/home/mnt/guest1\"\n",
    "path = \"./config/file_path.json\"\n",
    "file_path = None\n",
    "with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    file_path = json.load(fp)\n",
    "\n",
    "# # bigshane_local\n",
    "# dataset_dir = \"D:\\_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # AWS\n",
    "# dataset_dir = \"/home/ubuntu/data\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdf17a-12fc-44ec-ba99-501beaad5038",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc2f9cb-4b92-406f-b548-53e06d3f5bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:58:00.536308Z",
     "start_time": "2021-09-27T06:58:00.086856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained huggingface_tokenizer: 'D:\\_jupyter/huggingface_tokenizer/kor/kogpt2-vanila'\n",
      "vocab_size: 51200\n"
     ]
    }
   ],
   "source": [
    "tokenizer_file_path = dataset_dir + \"/huggingface_tokenizer/kor/kogpt2-vanila\"\n",
    "\n",
    "# # save tokenizer to local\n",
    "# tokenizer_path = \"skt/kogpt2-base-v2\"\n",
    "# add_special_token = True\n",
    "# tokenizer = make_custom_tokenizer_from_pretrained(model_type=\"gpt2\", name_or_path=tokenizer_path, add_special_token=add_special_token)\n",
    "# tokenizer.save_pretrained(tokenizer_file_path)\n",
    "\n",
    "tokenizer = load_tokenizer_from_pretrained(model_type=\"gpt2\", name_or_path=tokenizer_file_path)\n",
    "print(\"vocab_size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b3009-a177-4624-a554-a3fddea21e08",
   "metadata": {},
   "source": [
    "### Load Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36b094b-c777-41c7-ad6b-3b28ac1f8949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:58:07.339418Z",
     "start_time": "2021-09-27T06:58:00.537308Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data: 100%|█████████████████████████████████████████████████████████| 3907/3907 [00:06<00:00, 593.76it/s]\n"
     ]
    }
   ],
   "source": [
    "timesteps = 128\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "nprocs = 1\n",
    "use_condition = True\n",
    "alpha_blending = 0.5\n",
    "\n",
    "dataset_name = \"four_n2x8_both\"\n",
    "total_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/\".format(dataset_name)\n",
    "sample_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/sample/\".format(dataset_name)\n",
    "train_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/train/\".format(dataset_name)\n",
    "val_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/val/\".format(dataset_name)\n",
    "test_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/test/\".format(dataset_name)\n",
    "\n",
    "train_dataset = GptDatasetFromDir(data_dir=train_data_dir, tokenizer=tokenizer, timesteps=timesteps, batch_size=batch_size, device=device, nprocs=nprocs, use_condition=use_condition, alpha_blending=alpha_blending)\n",
    "train_data_loader = GeneratorDataLoader(dataset=train_dataset, batch_size=batch_size, device=device)\n",
    "\n",
    "val_dataset = GptDatasetFromDir(data_dir=val_data_dir, tokenizer=tokenizer, timesteps=timesteps, batch_size=batch_size, device=device, nprocs=nprocs, use_condition=False, alpha_blending=-1)\n",
    "val_data_loader = GeneratorDataLoader(dataset=val_dataset, batch_size=batch_size, device=device)\n",
    "\n",
    "test_dataset = GptDatasetFromDir(data_dir=test_data_dir, tokenizer=tokenizer, timesteps=timesteps, batch_size=batch_size, device=device, nprocs=nprocs, use_condition=False, alpha_blending=-1)\n",
    "test_data_loader = GeneratorDataLoader(dataset=test_dataset, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe63d7-3080-45b6-812b-ce516de12545",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f246a-2c86-4af4-8065-15a79e94ed6c",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b13aa2-8333-46c5-9f47-e24d834fe61c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:58:21.591256Z",
     "start_time": "2021-09-27T06:58:13.418003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'temp_dir' has been set to './20210927_155813/' to save model while training\n",
      "Setting model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpt2 = Gpt2(vocab_size=len(tokenizer))\n",
    "optimizer = gpt2.get_optimizer(lr=5e-5)\n",
    "\n",
    "gpt2 = set_device(gpt2, device=device)\n",
    "optimizer = set_device(optimizer, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7357d-7689-4113-b9d9-80fc720d37ec",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123a8f1-df76-459f-8893-5aa36030c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069f5d2-02b9-4b2b-b1d9-65ad0828d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "model_dir = dataset_dir + \"/model/gpt2/v2/non_condition/{dataset_name}/\".format(dataset_name=dataset_name)\n",
    "init_path(model_dir, True)\n",
    "\n",
    "metrics = [\"bleu\", \"meteor\", \"rouge\", \"semantic_score\"]\n",
    "bleu_ngrams = [3, 4]\n",
    "rouge_types = [\"1\", \"2\", \"L\"]\n",
    "name_or_path = \"beomi/kcbert-base\"\n",
    "decoding_method = \"beam_search\"\n",
    "\n",
    "train_history = TrainHistory()\n",
    "val_history = TrainHistory()\n",
    "for _epoch in range(1, epoch+1):\n",
    "    # train\n",
    "    epoch_train_history = gpt2.iteration_epoch(data_loader=train_data_loader, optimizer=optimizer, device=device, train=True, verbose_per_batch=-1)\n",
    "    # compute scores\n",
    "    train_scores = gpt2.compute_scores(metrics=metrics, data_loader=train_data_loader, device=device, tokenizer=tokenizer, timesteps=timesteps, bleu_ngrams=bleu_ngrams, rouge_types=rouge_types, name_or_path=name_or_path, decoding_method=decoding_method)\n",
    "    for metric, metric_score in train_scores.items():\n",
    "        epoch_train_history._add_acc(name=metric, value=metric_score)\n",
    "    \n",
    "    epoch_train_history_str = gpt2.verbose_template.format(mode=\"Epoch_train\", device=device, idx=_epoch, num_iters=epoch) + str(epoch_train_history)\n",
    "    print(epoch_train_history_str)\n",
    "    train_history += epoch_train_history\n",
    "    \n",
    "    # val\n",
    "    epoch_val_history = gpt2.iteration_epoch(data_loader=val_data_loader, optimizer=optimizer, device=device, train=False, verbose_per_batch=-1)\n",
    "    # compute scores\n",
    "    val_scores = gpt2.compute_scores(metrics=metrics, data_loader=val_data_loader, device=device, tokenizer=tokenizer, timesteps=timesteps, bleu_ngrams=bleu_ngrams, rouge_types=rouge_types, name_or_path=name_or_path, decoding_method=decoding_method)\n",
    "    for metric, metric_score in val_scores.items():\n",
    "        epoch_val_history._add_acc(name=metric, value=metric_score)\n",
    "    \n",
    "    epoch_val_history_str = gpt2.verbose_template.format(mode=\"Epoch_val\", device=device, idx=_epoch, num_iters=epoch) + str(epoch_val_history)\n",
    "    print(epoch_val_history_str)\n",
    "    val_history += epoch_val_history\n",
    "    \n",
    "    gpt2.save(path=model_dir + \"epoch_{}/\".format(_epoch), optimizer=optimizer, tokenizer=tokenizer)\n",
    "    with open(model_dir+\"log.txt\", \"a\", encoding=\"utf-8\") as fp: \n",
    "        fp.write(epoch_train_history_str + \"\\n\")\n",
    "        fp.write(epoch_val_history_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7b9dd-22d9-48c6-961c-097ef45d8d02",
   "metadata": {},
   "source": [
    "### Compute Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25d8073-b857-440a-ab78-8ec09d6cec18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T07:07:40.371464Z",
     "start_time": "2021-09-27T06:58:21.596257Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc3722a6ef06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"KoGPT2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/model/gpt2/{}/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/essay/gpt2/ft_o_rt_x/{dataset_name}/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minit_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_dir' is not defined"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "metrics = [\"bleu\", \"meteor\", \"rouge\", \"semantic_score\"]\n",
    "bleu_ngrams = [3, 4]\n",
    "rouge_types = [\"1\", \"2\", \"L\"]\n",
    "name_or_path = \"beomi/kcbert-base\"\n",
    "decoding_method = \"beam_search\"\n",
    "model_name = \"KoGPT2\"\n",
    "\n",
    "model_dir = dataset_dir + \"/model/gpt2/v2/{dataset_name}/\".format(dataset_name=dataset_name)\n",
    "log_dir = dataset_dir + \"/essay/gpt2/ft_o_rt_o/condition/{dataset_name}/\".format(dataset_name=dataset_name)\n",
    "init_path(log_dir, reset=True)\n",
    "for _epoch in range(1, epoch+1):\n",
    "    gpt2 = load_state_dict(object=gpt2, path=model_dir+\"epoch_{}/\".format(_epoch))\n",
    "    scores = gpt2.compute_scores(metrics=metrics, data_loader=test_data_loader, device=device, tokenizer=tokenizer, timesteps=timesteps, bleu_ngrams=bleu_ngrams, rouge_types=rouge_types, name_or_path=name_or_path, decoding_method=decoding_method)\n",
    "    output_json = get_score_json(model_name=model_name, dataset_name=dataset_name, test_data_size=len(test_data_loader.dataset), batch_size=batch_size, scores=scores)\n",
    "\n",
    "    # verbose & append log\n",
    "    eval_history = TrainHistory()\n",
    "    loss_dict = dict()\n",
    "    acc_dict = dict()\n",
    "    for metric, score in scores.items():\n",
    "        acc_dict[metric] = score\n",
    "    eval_history.update(loss_dict=loss_dict, acc_dict=acc_dict, lr=-1)\n",
    "    eval_str = gpt2.verbose_template.format(mode=\"Eval\", device=device, idx=_epoch, num_iters=epoch) + str(eval_history)\n",
    "    print(eval_str)\n",
    "\n",
    "    with open(log_dir + \"/score_logs.txt\", \"a\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(eval_str + \"\\n\")\n",
    "\n",
    "    # write detailed logs\n",
    "    init_path(log_dir + \"/detailed/\", reset=False)\n",
    "    with open(log_dir + \"/detailed/score_logs_{_epoch}.json\".format(_epoch=_epoch), \"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dumps(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c97be-4c17-421d-a70f-d1066e81fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_epoch = 5\n",
    "model_dir = dataset_dir + \"/model/gpt2/v2/condition/{}/\".format(dataset_name)\n",
    "gpt2 = load_state_dict(object=gpt2, path=model_dir+\"epoch_{}/\".format(_epoch))\n",
    "epoch_val_history = gpt2.iteration_epoch(data_loader=test_data_loader, optimizer=optimizer, device=device, train=False, verbose_per_batch=-1)\n",
    "print(epoch_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2c54d-e2c4-400d-8130-abc17390117f",
   "metadata": {},
   "source": [
    "### Test Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe82b2-6054-46c2-a8aa-efc96c02e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.services.dialog_generator.gpt2 import Gpt2DialogGenerator\n",
    "service = Gpt2DialogGenerator()\n",
    "service.verbose = False\n",
    "service.set_device(device=device)\n",
    "_epoch = 5\n",
    "_model_dir = dataset_dir + \"/model/gpt2/v2/condition//{dataset_name}/epoch_{_epoch}\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "service.load_model(model_dir=_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27c681-f030-4b14-b7f7-6832e554c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    \"안녕하세요\",\n",
    "#     \"무슨 일로 저에게 상담을 신청하셨나요?\"\n",
    "#     \"요즘 인간관계가 고민이에요.\",\n",
    "#     \"어떤 고민이죠?\",\n",
    "#     \"친구들이랑 연락도 뜸해지고 자주 못만나서 서먹해지는 것 같아요\",\n",
    "#     \"이래저래 연락하기 힘드신가봐요\",\n",
    "#     \"네, 코로나 때문에 만나질 못해서 더 혼자가 된 느낌이에요.\",\n",
    "#     \"저도 지쳐요.\",\n",
    "#     \"당신도 사람들을 자주 못 만나시나봐요\"\n",
    " ]\n",
    "speaker_ids = [(i+1)%2 for i in range(len(utterances))]\n",
    "\n",
    "outputs = service.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                   min_length=10, top_n=5, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                   beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2eb20-14b9-4f43-973e-4e185f86f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    \"오늘 하루가 정말 피곤하네요\",\n",
    "#     \"무슨 일이 있으셨죠? 오늘 하루는 어떠셨어요?\"\n",
    "#     \"회사에서 일이 너무 많았어요.\",\n",
    "#     \"많이 힘드셨겠어요 힘내세요\",\n",
    "#     \"고마워요. 게다가 요즘 상사에게 자꾸 혼나요.\",\n",
    "#     \"왜  혼나는 일들이 쌓이셨나요?\",\n",
    "#     \"저번에 시키신 일을 제대로 못했거든요.\",\n",
    "#     \"어떤 일이 있었는지 말해주실 수 있나요?\",\n",
    "#     \"제가 서류를 잘못 가져다드렸어요.\"\n",
    " ]\n",
    "speaker_ids = [(i+1)%2 for i in range(len(utterances))]\n",
    "\n",
    "outputs = service.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                   min_length=10, top_n=5, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                   beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3403a-f592-4610-8ab3-e3c385676947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33cd59-864f-446f-8415-3a46addad088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5f1a4-9251-4446-a156-c2cbe90991c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a1929d9-302b-4ecf-85f6-39f9b2f7d664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T11:49:16.462038Z",
     "start_time": "2021-09-07T11:49:16.011180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'말하신대로 해볼게요. 제가 할 수 있을까요?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances = [\n",
    "    \"안녕하세요\",\n",
    "#     \"무슨 일로 저에게 상담을 신청하셨나요?\"\n",
    "#     \"요즘 인간관계가 고민이에요.\",\n",
    "#     \"어떤 고민이죠?\",\n",
    "#     \"친구들이랑 연락도 뜸해지고 자주 못만나서 서먹해지는 것 같아요\",\n",
    "#     \"이래저래 연락하기 힘드신가봐요\",\n",
    "#     \"네, 코로나 때문에 만나질 못해서 더 혼자가 된 느낌이에요.\",\n",
    "#     \"저도 지쳐요.\",\n",
    "#     \"당신도 사람들을 자주 못 만나시나봐요\"\n",
    " ]\n",
    "\n",
    "text = \" \".join(utterances)\n",
    "input_ids = tokenizer.encode(text)\n",
    "input_ids = input_ids + [tokenizer.bos_token_id]\n",
    "input_ids = convert_to_tensor([input_ids], device=device)\n",
    "\n",
    "begin_idx = len(input_ids[0])\n",
    "beam_output = gpt2.generate(input_ids=input_ids, \n",
    "    max_length=timesteps,\n",
    "    min_length=15,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_beams=10, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "tokenizer.decode(beam_output[:, begin_idx:-1].tolist()[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b5dc3-91c9-456c-942a-a922a4db118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_n2x8_one -> epoch_3가 베스트 (1)\n",
    "selectstar_n2x8_one -> epoch_4가 베스트 (2)\n",
    "four_n2x8_both -> epoch_3가 베스트 (4)\n",
    "selectstar_n2x8_both -> epoch_2가 베스트 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c6a69-f0a5-4887-8ca2-ad330a91db6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a754d-61d3-4528-91c9-04b6ee0f9602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d0847e2-8a8e-49d1-9e2b-8affce66693f",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6f040-8e07-45a0-a797-cb2e57d174d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.services.dialog_generator.bart import BartDialogGenerator\n",
    "generator = BartDialogGenerator()\n",
    "generator.verbose = False\n",
    "_epoch = 6\n",
    "generator.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/bart/v2/condition_bm25/{dataset_name}/epoch_{_epoch}\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "generator.load_model(model_dir=_model_dir)\n",
    "\n",
    "from transformer.services.dialog_retriever.poly_encoder import PolyEncoderDialogRetriever\n",
    "retriever = PolyEncoderDialogRetriever()\n",
    "retriever.verbose = False\n",
    "_epoch = 34\n",
    "retriever.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/poly_encoder/v2/{dataset_name}/epoch_{_epoch}/\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "retriever.load_model(model_dir=_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeafd54-1991-43da-bf6d-b0b19237e810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:43:06.673073Z",
     "start_time": "2021-09-27T06:43:06.662965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bleu', 'rouge1', 'rouge2', 'rougeL'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer.data.utils import simplify_speaker_ids\n",
    "from transformer.utils.common import get_last_index\n",
    "from KoBERTScore import BERTScore\n",
    "from transformer.models.utils import compute_bleu, compute_meteor, compute_rouge, compute_hits, compute_semantic_score\n",
    "\n",
    "def get_metric_inputs(dataset, min_length=1, top_n=10):\n",
    "    for row_idx in range(0, len(dataset.raw_data)):\n",
    "        output = None\n",
    "        \n",
    "        _utterances = dataset.raw_data[row_idx][\"utterances\"]\n",
    "        _speaker_ids = dataset.raw_data[row_idx][\"speaker_ids\"]\n",
    "        _speaker_ids = simplify_speaker_ids(_speaker_ids, user_id=1, model_id=0)\n",
    "        last_index = get_last_index(_speaker_ids, value=1)\n",
    "        utterances = _utterances[:last_index+1]\n",
    "        speaker_ids = _speaker_ids[:last_index+1]\n",
    "        reference = _utterances[last_index+1:]\n",
    "        reference = \" \".join(reference)\n",
    "\n",
    "        try:\n",
    "            context = \" \".join(utterances)\n",
    "            \n",
    "            # non_condition_prediction\n",
    "            outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                                 min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                                 beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "            non_condition_prediction = [output[0] for output in outputs][0]\n",
    "            \n",
    "            # condition_prediction\n",
    "            outputs = retriever.infer_next_utterance(utterances=utterances, speaker_ids=speaker_ids,\n",
    "                                       min_length=min_length, top_n=top_n, weight_bm25=False,\n",
    "                                       prev_utterance=None, intersection_tolerance=0.9, max_retry=5)\n",
    "            condition = outputs[0][0]\n",
    "            \n",
    "            outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=[condition],\n",
    "                                                                 min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                                 beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "            condition_prediction = [output[0] for output in outputs][0]\n",
    "\n",
    "            output = {\n",
    "                \"context\": context,\n",
    "                \"reference\": reference,\n",
    "                \"condition\": condition,\n",
    "                \"non_condition_prediction\": non_condition_prediction,\n",
    "                \"condition_prediction\": condition_prediction\n",
    "            }\n",
    "            yield output\n",
    "        except:\n",
    "            yield output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a23134-504d-4c95-8512-d4ef4c645dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(model, tokenizer, predictions, references):\n",
    "    scores = dict()\n",
    "    _scores = dict()\n",
    "    if \"bleu\" in metrics:\n",
    "        _scores[\"bleu\"] = compute_bleu(metric=model.metrics[\"bleu\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    if \"meteor\" in metrics:\n",
    "        _scores[\"meteor\"] = compute_meteor(metric=model.metrics[\"meteor\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    if \"rouge\" in metrics:\n",
    "        _scores[\"rouge\"] = compute_rouge(metric=model.metrics[\"rouge\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    if \"semantic_score\" in metrics:\n",
    "        _scores[\"semantic_score\"] = compute_semantic_score(metric=model.metrics[\"semantic_score\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    \n",
    "    if \"bleu\" in metrics:\n",
    "        _bleu_scores = _scores[\"bleu\"][\"precisions\"]\n",
    "        for ngram in bleu_ngrams:\n",
    "            name = \"BLEU-{n}\".format(n=ngram)\n",
    "            score = _bleu_scores[ngram-1]\n",
    "            score = round(score, 4)\n",
    "            scores[name] = score\n",
    "    if \"meteor\" in metrics:\n",
    "        score = _scores[\"meteor\"][\"meteor\"]\n",
    "        score = round(score, 4)\n",
    "        scores[\"METEOR\"] = score\n",
    "    if \"rouge\" in metrics:\n",
    "        for r in rouge_types:\n",
    "            key = \"rouge{r}\".format(r=r)\n",
    "            if key in _scores[\"rouge\"]:\n",
    "                name = \"ROUGE-{r}\".format(r=r)\n",
    "                score = _scores[\"rouge\"][key]\n",
    "                score = score.mid.fmeasure\n",
    "                score = round(score, 4)\n",
    "                scores[name] = score\n",
    "    if \"hits\" in metrics:\n",
    "        for k, score in zip(hits_k, _scores[\"hits\"]):\n",
    "            name = \"HITS@{k}\".format(k=k)\n",
    "            score = round(score, 4)\n",
    "            scores[name] = score\n",
    "    if \"semantic_score\" in metrics:\n",
    "        name = \"BERTScore\".format(name_or_path=name_or_path)\n",
    "        score = _scores[\"semantic_score\"]\n",
    "        score = round(score, 4)\n",
    "        scores[name] = score\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38064209-7c50-47f9-aac0-961c7082c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"bleu\", \"meteor\", \"rouge\", \"semantic_score\"]\n",
    "bleu_ngrams = [3, 4]\n",
    "rouge_types = [\"1\", \"2\", \"L\"]\n",
    "name_or_path = \"beomi/kcbert-base\"\n",
    "decoding_method = \"beam_search\"\n",
    "min_length = 10\n",
    "top_n = 5\n",
    "\n",
    "metric_input_gen = get_metric_inputs(dataset=test_dataset, min_length=min_length, top_n=top_n)\n",
    "\n",
    "non_condition_predictions = []\n",
    "condition_predictions = []\n",
    "references = []\n",
    "for gen_output in tqdm(metric_input_gen):\n",
    "    if gen_output is None: continue\n",
    "    references.append(gen_output[\"reference\"])\n",
    "    non_condition_predictions.append(gen_output[\"non_condition_prediction\"])\n",
    "    condition_predictions.append(gen_output[\"condition_prediction\"])\n",
    "\n",
    "non_condition_scores = compute_scores(model=bart, tokenizer=tokenizer, predictions=non_condition_predictions, references=references)\n",
    "print(\"non_condition_score:\", non_condition_score)\n",
    "\n",
    "condition_scores = compute_scores(model=bart, tokenizer=tokenizer, predictions=condition_predictions, references=references)\n",
    "print(\"condition_scores:\", condition_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
