{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b12321-7937-454e-9631-af3779b77cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T10:27:32.076193Z",
     "start_time": "2021-09-09T10:27:32.061813Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from setproctitle import setproctitle\n",
    "setproctitle(\"Hodong_BART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce58bd57-8f4c-4dbe-8338-a25fb10e02b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T10:27:33.832662Z",
     "start_time": "2021-09-09T10:27:32.077195Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import BartModel\n",
    "from transformers import BartForConditionalGeneration\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformer.data.generator_dataset import BartDatasetFromDir, GeneratorDataLoader\n",
    "from transformer.tokenizer.utils import make_custom_tokenizer_from_pretrained, load_tokenizer_from_pretrained\n",
    "from transformer.models.interface import TrainHistory\n",
    "from transformer.models.bart import Bart\n",
    "from transformer.models.utils import load_state_dict, get_score_json\n",
    "from transformer.utils.common import set_device, convert_to_tensor, init_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c034302-9172-4313-a6ee-ba3c95faf5e3",
   "metadata": {},
   "source": [
    "### Set WorkingDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aab427e-aed9-48c3-a9b5-9bf5ee7f746f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T10:27:33.847846Z",
     "start_time": "2021-09-09T10:27:33.835628Z"
    }
   },
   "outputs": [],
   "source": [
    "# # AIBUD_DEV\n",
    "# dataset_dir = \"/Users/aibud_dev/_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# Korea_Server\n",
    "dataset_dir = \"/home/mnt/guest1\"\n",
    "path = \"./config/file_path.json\"\n",
    "file_path = None\n",
    "with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    file_path = json.load(fp)\n",
    "\n",
    "# # bigshane_local\n",
    "# dataset_dir = \"D:\\_jupyter\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)\n",
    "\n",
    "# # AWS\n",
    "# dataset_dir = \"/home/ubuntu/data\"\n",
    "# path = \"./config/file_path.json\"\n",
    "# file_path = None\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "#     file_path = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880c45a-9665-4485-9871-1ef5068c41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef24e01-3f6c-4e62-8ef1-224eaae8b21e",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acacaca-6d39-48ca-ab98-c787ba257a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T10:27:34.042957Z",
     "start_time": "2021-09-09T10:27:33.848852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update unregistered special_tokens to class_variables:{'num_token': '<num>', 'num_token_id': 30000, 'cls_token': '<cls>', 'cls_token_id': 30001, 'sep_token': '<sep>', 'sep_token_id': 30002, 'turn_token': '<turn>', 'turn_token_id': 30003, 'topic_token': '<tpc>', 'topic_token_id': 30004, 'situation_token': '<situ>', 'situation_token_id': 30005, 'context_token': '<ctxt>', 'context_token_id': 30006, 'condition_token': '<cond>', 'condition_token_id': 30007, 'candidate_token': '<cand>', 'candidate_token_id': 30008, 'persona_token': '<pers>', 'persona_token_id': 30009, 'speaker_1_token': '<spk1>', 'speaker_1_token_id': 30010, 'speaker_2_token': '<spk2>', 'speaker_2_token_id': 30011}\n",
      "loaded pretrained huggingface_tokenizer: '/Users/aibud_dev/_jupyter/huggingface_tokenizer/kor/kobart-customed'\n",
      "vocab_size: 30012\n"
     ]
    }
   ],
   "source": [
    "tokenizer_file_path = dataset_dir + \"/huggingface_tokenizer/kor/kobart-vanila\"\n",
    "\n",
    "# # save tokenizer to local\n",
    "# tokenizer_path = \"hyunwoongko/kobart\"\n",
    "# add_special_token = True\n",
    "# tokenizer = make_custom_tokenizer_from_pretrained(model_type=\"bart\", name_or_path=tokenizer_path, add_special_token=add_special_token)\n",
    "# tokenizer.save_pretrained(tokenizer_file_path)\n",
    "\n",
    "tokenizer = load_tokenizer_from_pretrained(model_type=\"bart\", name_or_path=tokenizer_file_path)\n",
    "print(\"vocab_size:\", len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934cc2b-4a45-43f0-8da0-d16085f77023",
   "metadata": {},
   "source": [
    "### Load Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822b0b08-b3c3-4701-af52-22bcac5b6df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T10:27:39.131350Z",
     "start_time": "2021-09-09T10:27:34.043996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data: 100%|██████████| 5000/5000 [00:09<00:00, 534.64it/s]\n",
      "Preprocessing data: 100%|██████████| 5000/5000 [00:08<00:00, 572.00it/s]\n"
     ]
    }
   ],
   "source": [
    "timesteps = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "nprocs = 1\n",
    "use_condition = True\n",
    "alpha_blending = 0.5\n",
    "\n",
    "dataset_name = \"four_n2x8_both\"\n",
    "total_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/\".format(dataset_name)\n",
    "sample_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/sample/\".format(dataset_name)\n",
    "train_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/train/\".format(dataset_name)\n",
    "val_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/val/\".format(dataset_name)\n",
    "test_data_dir = dataset_dir + \"/dataset/preprocessed/dialog_finetuning/kor/condition/{}/test/\".format(dataset_name)\n",
    "\n",
    "train_dataset = BartDatasetFromDir(data_dir=train_data_dir, tokenizer=tokenizer, timesteps=timesteps, batch_size=batch_size, device=device, nprocs=nprocs, use_condition=use_condition, alpha_blending=alpha_blending)\n",
    "train_data_loader = GeneratorDataLoader(dataset=train_dataset, batch_size=batch_size, device=device)\n",
    "\n",
    "val_dataset = BartDatasetFromDir(data_dir=val_data_dir, tokenizer=tokenizer, timesteps=timesteps, batch_size=batch_size, device=device, nprocs=nprocs, use_condition=False, alpha_blending=-1)\n",
    "val_data_loader = GeneratorDataLoader(dataset=val_dataset, batch_size=batch_size, device=device)\n",
    "\n",
    "test_dataset = BartDatasetFromDir(data_dir=test_data_dir, tokenizer=tokenizer, timesteps=timesteps, batch_size=batch_size, device=device, nprocs=nprocs, use_condition=False, alpha_blending=-1)\n",
    "test_data_loader = GeneratorDataLoader(dataset=test_dataset, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c824317-4f61-4b27-a103-5d86d266a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2fdcc-2623-4b0c-b96e-70e78a74479c",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57a2515-8782-488e-8014-266ba6b7d559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T10:27:43.174630Z",
     "start_time": "2021-09-09T10:27:39.132348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'temp_dir' has been set to './20210909_192739/' to save model while training\n",
      "Setting model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "bart = Bart(vocab_size=len(tokenizer))\n",
    "optimizer = bart.get_optimizer(lr=5e-5)\n",
    "\n",
    "bart = set_device(bart, device=device)\n",
    "optimizer = set_device(optimizer, device=device)\n",
    "\n",
    "# # continue learning\n",
    "# _model_dir = dataset_dir + \"/model/bart/four_n2x8_both/epoch_{}/\".format(7)\n",
    "# bart = load_state_dict(object=bart, path=_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a83c34-2e0d-4fdf-bdf9-1cc8002e873d",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a739c-852c-4d34-87dc-eb6cbed25a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ae957-1a81-4ef8-82d7-79b58bd9aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "model_dir = dataset_dir + \"/model/bart/v2/{dataset_name}/\".format(dataset_name=dataset_name)\n",
    "init_path(model_dir, True)\n",
    "\n",
    "metrics = [\"bleu\", \"meteor\", \"rouge\", \"semantic_score\"]\n",
    "bleu_ngrams = [3, 4]\n",
    "rouge_types = [\"1\", \"2\", \"L\"]\n",
    "name_or_path = \"beomi/kcbert-base\"\n",
    "decoding_method = \"beam_search\"\n",
    "\n",
    "train_history = TrainHistory()\n",
    "val_history = TrainHistory()\n",
    "for _epoch in range(1, epoch+1):\n",
    "    # train\n",
    "    epoch_train_history = bart.iteration_epoch(data_loader=train_data_loader, optimizer=optimizer, device=device, train=True, verbose_per_batch=-1)\n",
    "    # compute scores\n",
    "    train_scores = bart.compute_scores(metrics=metrics, data_loader=train_data_loader, device=device, tokenizer=tokenizer, timesteps=timesteps, bleu_ngrams=bleu_ngrams, rouge_types=rouge_types, name_or_path=name_or_path, decoding_method=decoding_method)\n",
    "    for metric, metric_score in train_scores.items():\n",
    "        epoch_train_history._add_acc(name=metric, value=metric_score)\n",
    "        \n",
    "    epoch_train_history_str = bart.verbose_template.format(mode=\"Epoch_train\", device=device, idx=_epoch, num_iters=epoch) + str(epoch_train_history)\n",
    "    print(epoch_train_history_str)\n",
    "    train_history += epoch_train_history\n",
    "    \n",
    "    # val\n",
    "    epoch_val_history = bart.iteration_epoch(data_loader=val_data_loader, optimizer=optimizer, device=device, train=False, verbose_per_batch=-1)\n",
    "    # compute scores\n",
    "    val_scores = bart.compute_scores(metrics=metrics, data_loader=val_data_loader, device=device, tokenizer=tokenizer, timesteps=timesteps, bleu_ngrams=bleu_ngrams, rouge_types=rouge_types, name_or_path=name_or_path, decoding_method=decoding_method)\n",
    "    for metric, metric_score in val_scores.items():\n",
    "        epoch_val_history._add_acc(name=metric, value=metric_score)\n",
    "        \n",
    "    epoch_val_history_str = bart.verbose_template.format(mode=\"Epoch_val\", device=device, idx=_epoch, num_iters=epoch) + str(epoch_val_history)\n",
    "    print(epoch_val_history_str)\n",
    "    val_history += epoch_val_history\n",
    "    \n",
    "    bart.save(path=model_dir + \"epoch_{}/\".format(_epoch), optimizer=optimizer, tokenizer=tokenizer)\n",
    "    with open(model_dir+\"log.txt\", \"a\", encoding=\"utf-8\") as fp: \n",
    "        fp.write(epoch_train_history_str + \"\\n\")\n",
    "        fp.write(epoch_val_history_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b3bda-e1c3-4296-82e8-45b5448aa8ba",
   "metadata": {},
   "source": [
    "### Compute Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9dfb2-4759-409c-97c5-c0ffe16b63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "metrics = [\"bleu\", \"meteor\", \"rouge\", \"semantic_score\"]\n",
    "bleu_ngrams = [3, 4]\n",
    "rouge_types = [\"1\", \"2\", \"L\"]\n",
    "name_or_path = \"beomi/kcbert-base\"\n",
    "decoding_method = \"beam_search\"\n",
    "model_name = \"KoBART\"\n",
    "\n",
    "model_dir = dataset_dir + \"/model/bart/{}/\".format(dataset_name)\n",
    "log_dir = dataset_dir + \"/essay/bart/ft_o_rt_x/{dataset_name}/\".format(dataset_name=dataset_name)\n",
    "init_path(log_dir, reset=True)\n",
    "for _epoch in range(1, epoch+1):\n",
    "    bart = load_state_dict(object=bart, path=model_dir+\"epoch_{}/\".format(_epoch))\n",
    "    scores = bart.compute_scores(metrics=metrics, data_loader=test_data_loader, device=device, tokenizer=tokenizer, timesteps=timesteps, bleu_ngrams=bleu_ngrams, rouge_types=rouge_types, name_or_path=name_or_path, decoding_method=decoding_method)\n",
    "    output_json = get_score_json(model_name=model_name, dataset_name=dataset_name, test_data_size=len(test_data_loader.dataset), batch_size=batch_size, scores=scores)\n",
    "\n",
    "    # verbose & append log\n",
    "    eval_history = TrainHistory()\n",
    "    loss_dict = dict()\n",
    "    acc_dict = dict()\n",
    "    for metric, score in scores.items():\n",
    "        acc_dict[metric] = score\n",
    "    eval_history.update(loss_dict=loss_dict, acc_dict=acc_dict, lr=-1)\n",
    "    eval_str = bart.verbose_template.format(mode=\"Eval\", device=device, idx=_epoch, num_iters=epoch) + str(eval_history)\n",
    "    print(eval_str)\n",
    "\n",
    "    with open(log_dir + \"/score_logs.txt\", \"a\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(eval_str + \"\\n\")\n",
    "\n",
    "    # write detailed logs\n",
    "    init_path(log_dir + \"/detailed/\", reset=False)\n",
    "    with open(log_dir + \"/detailed/score_logs_{_epoch}.json\".format(_epoch=_epoch), \"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dumps(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781009d3-b336-4296-98b5-99457ef5fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_epoch = 5\n",
    "model_dir = dataset_dir + \"/model/gpt2/v2/condition/{}/\".format(dataset_name)\n",
    "gpt2 = load_state_dict(object=gpt2, path=model_dir+\"epoch_{}/\".format(_epoch))\n",
    "epoch_val_history = gpt2.iteration_epoch(data_loader=test_data_loader, optimizer=optimizer, device=device, train=False, verbose_per_batch=-1)\n",
    "print(epoch_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfff23f-cd3f-497c-88e2-6ccddcc4e0a8",
   "metadata": {},
   "source": [
    "### Test Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746f4a8-55c9-419f-98f8-d38bbab3d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.services.dialog_generator.bart import BartDialogGenerator\n",
    "service = BartDialogGenerator()\n",
    "service.verbose = False\n",
    "_epoch = 6\n",
    "service.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/bart/v2/condition/{dataset_name}/epoch_{_epoch}\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "service.load_model(model_dir=_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e3969-96cf-4a90-ad49-590fe9b6bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    \"안녕하세요\",\n",
    "#     \"무슨 일로 저에게 상담을 신청하셨나요?\"\n",
    "#     \"요즘 인간관계가 고민이에요.\",\n",
    "#     \"어떤 고민이죠?\",\n",
    "#     \"친구들이랑 연락도 뜸해지고 자주 못만나서 서먹해지는 것 같아요\",\n",
    "#     \"이래저래 연락하기 힘드신가봐요\",\n",
    "#     \"네, 코로나 때문에 만나질 못해서 더 혼자가 된 느낌이에요.\",\n",
    "#     \"저도 지쳐요.\",\n",
    "#     \"당신도 사람들을 자주 못 만나시나봐요\"\n",
    " ]\n",
    "speaker_ids = [(i+1)%2 for i in range(len(utterances))]\n",
    "\n",
    "outputs = service.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                   min_length=10, top_n=5, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                   beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a02af0-de7c-41e3-a7bd-aded4273e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    \"오늘 하루가 정말 피곤하네요\",\n",
    "#     \"무슨 일이 있으셨죠? 오늘 하루는 어떠셨어요?\"\n",
    "#     \"회사에서 일이 너무 많았어요.\",\n",
    "#     \"많이 힘드셨겠어요 힘내세요\",\n",
    "#     \"고마워요. 게다가 요즘 상사에게 자꾸 혼나요.\",\n",
    "#     \"왜  혼나는 일들이 쌓이셨나요?\",\n",
    "#     \"저번에 시키신 일을 제대로 못했거든요.\",\n",
    "#     \"어떤 일이 있었는지 말해주실 수 있나요?\",\n",
    "#     \"제가 서류를 잘못 가져다드렸어요.\"\n",
    " ]\n",
    "speaker_ids = [(i+1)%2 for i in range(len(utterances))]\n",
    "\n",
    "outputs = service.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                   min_length=10, top_n=5, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                   beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "outputs[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c2425-aaf1-47ee-a179-ed306407c82e",
   "metadata": {},
   "source": [
    "### Conditional Generatio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8dab2-b933-4c37-a68d-230d7fb150c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.services.dialog_generator.bart import BartDialogGenerator\n",
    "generator = BartDialogGenerator()\n",
    "generator.verbose = False\n",
    "_epoch = 6\n",
    "generator.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/bart/v2/condition/{dataset_name}/epoch_{_epoch}\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "generator.load_model(model_dir=_model_dir)\n",
    "\n",
    "from transformer.services.dialog_retriever.poly_encoder import PolyEncoderDialogRetriever\n",
    "retriever = PolyEncoderDialogRetriever()\n",
    "retriever.verbose = False\n",
    "_epoch = 34\n",
    "retriever.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/poly_encoder/v2/{dataset_name}/epoch_{_epoch}/\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "retriever.load_model(model_dir=_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e044903-6f13-4a3b-9214-fcd6bc400b4b",
   "metadata": {},
   "source": [
    "#### manual input test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e235dd5-0b56-4597-91d6-dccae61beaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = [\n",
    "    \"하루가 너무 피곤하네요\",\n",
    "    \"너무 피곤하지 않으셨으면 좋게썽요\",\n",
    "    \"그럴 수 있을까요? 그치만 업무가 너무 많아서요\",\n",
    "    \"업무가 너무 많아서 힘드시군요\",\n",
    "    \"네... 도무지 끝날 기미가 안보이고 계속 일이 들어와요\",\n",
    "    \"너무 안타깝네요 빨리 업무가 익숙해져야 할텐데요,,\",\n",
    "    \"제가 익숙하지 않아서 그런걸까요? 보면 선배들은 빨리빨리 하긴 하더라구요.\",\n",
    "    \"어떤 점이 가장 힘드신가요?\",\n",
    "    \"계속 멀어지는 것 같고, 그러다보니 외로워서요\"\n",
    " ]\n",
    "speaker_ids = [(i+1)%2 for i in range(len(utterances))]\n",
    "min_length = 10\n",
    "top_n = 5\n",
    "\n",
    "outputs = retriever.infer_next_utterance(utterances=utterances, speaker_ids=speaker_ids,\n",
    "                                       min_length=min_length, top_n=top_n, weight_bm25=False,\n",
    "                                       prev_utterance=None, intersection_tolerance=0.9, max_retry=5)\n",
    "print(\"condition:\", outputs[0])\n",
    "condition = outputs[0][0]\n",
    "\n",
    "# Non-condition\n",
    "outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                   min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                   beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "non_condition_output = outputs[0][0]\n",
    "print(\"non-condition-gen:\", non_condition_output)\n",
    "\n",
    "# Condition\n",
    "outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=[condition],\n",
    "                                                   min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                   beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "condition_output = outputs[0][0]\n",
    "print(\"condition-gen:\", condition_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61de2b3-fdb1-4d7f-a27b-b267882b4621",
   "metadata": {},
   "source": [
    "#### dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e68d5-86a0-41a1-8a5e-0200a3691a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.data.utils import simplify_speaker_ids\n",
    "from transformer.utils.common import get_last_index\n",
    "\n",
    "def show_dataset_result(dataset, begin_idx=0, verbose=True):\n",
    "    for row_idx in range(begin_idx, len(dataset.raw_data)):\n",
    "        _utterances = dataset.raw_data[row_idx][\"utterances\"]\n",
    "        _speaker_ids = dataset.raw_data[row_idx][\"speaker_ids\"]\n",
    "        _speaker_ids = simplify_speaker_ids(_speaker_ids, user_id=1, model_id=0)\n",
    "        last_index = get_last_index(_speaker_ids, value=1)\n",
    "        utterances = _utterances[:last_index+1]\n",
    "        speaker_ids = _speaker_ids[:last_index+1]\n",
    "        reference = _utterances[last_index+1:]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"# {}\".format(row_idx))\n",
    "            for speaker_id, utterance in zip(speaker_ids, utterances):\n",
    "                print(\"{}: {}\".format(speaker_id, utterance))\n",
    "            print(\"\\nreference:\", reference)\n",
    "\n",
    "        min_length = 10\n",
    "        top_n = 5\n",
    "\n",
    "        output = None\n",
    "        try:\n",
    "            outputs = retriever.infer_next_utterance(utterances=utterances, speaker_ids=speaker_ids,\n",
    "                                                   min_length=min_length, top_n=top_n, weight_bm25=False,\n",
    "                                                   prev_utterance=None, intersection_tolerance=0.9, max_retry=5)\n",
    "            if verbose: print(\"condition:\", outputs[0])\n",
    "            condition = outputs[0][0]\n",
    "\n",
    "            # Non-condition\n",
    "            outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                               min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                               beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "            non_condition_output = outputs[0][0]\n",
    "            if verbose: print(\"non-condition-gen:\", non_condition_output)\n",
    "\n",
    "            # Condition\n",
    "            outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=[condition],\n",
    "                                                               min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                               beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "            condition_output = outputs[0][0]\n",
    "            if verbose: print(\"condition-gen:\", condition_output)\n",
    "\n",
    "            output = {\n",
    "                \"reference\": reference,\n",
    "                \"condition\": condition,\n",
    "                \"non-condition-gen\": non_condition_output,\n",
    "                \"condition-gen\": condition_output\n",
    "            }\n",
    "            yield output\n",
    "        except:\n",
    "            yield output\n",
    "        \n",
    "gen = show_dataset_result(dataset=test_dataset, begin_idx=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275dcc9-7817-4bc0-a57b-1eba8e7ed62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_output = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039bee6-a79c-41cc-bd74-5764ff4a2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = show_dataset_result(dataset=test_dataset, begin_idx=0, verbose=False)\n",
    "\n",
    "cnt_list = [0 for i in range(4)]\n",
    "item_list = [[] for i in range(4)]\n",
    "\n",
    "for gen_output in tqdm(test_gen, initial=0, total=len(test_dataset.raw_data)):\n",
    "    if gen_output is None: continue\n",
    "        \n",
    "    reference = gen_output[\"reference\"]\n",
    "    condition = gen_output[\"condition\"]\n",
    "    non_condition_gen = gen_output[\"non-condition-gen\"]\n",
    "    condition_gen = gen_output[\"condition-gen\"]\n",
    "\n",
    "    reference_token_set = set(tokenizer.encode(\" \".join(reference)))\n",
    "    condition_token_set = set(tokenizer.encode(condition))\n",
    "    non_condition_gen_token_set = set(tokenizer.encode(non_condition_gen))\n",
    "    condition_gen_token_set = set(tokenizer.encode(condition_gen))\n",
    "\n",
    "    condition_gen_intersection = len(condition_token_set.intersection(condition_gen_token_set)) / len(condition_token_set)\n",
    "    reference_cond_gen_intersection = len(reference_token_set.intersection(condition_gen_token_set)) / len(reference_token_set)\n",
    "    reference_non_cond_gen_intersection = len(reference_token_set.intersection(non_condition_gen_token_set)) / len(reference_token_set)\n",
    "\n",
    "    if condition_gen_intersection > 0.7: \n",
    "        if reference_cond_gen_intersection > 0.7:\n",
    "            # case 1: condition과 gen이 거의 같은 경우 (과도한 알파블렌딩) && ref를 잘 맞힌 경우\n",
    "            cnt_list[0] += 1\n",
    "            item_list[0].append(gen_output)\n",
    "        else:\n",
    "            # case 2: condition과 gen이 거의 같은 경우 (과도한 알파블렌딩) && ref를 못 맞힌 경우\n",
    "            cnt_list[1] += 1\n",
    "            item_list[1].append(gen_output)\n",
    "    else:\n",
    "        if reference_cond_gen_intersection > 0.7:\n",
    "            # case 3: condition과 gen이 다소 다른 경우 (과도한 알파블렌딩) && ref를 잘 맞힌 경우\n",
    "            cnt_list[2] += 1\n",
    "            item_list[2].append(gen_output)\n",
    "        else:\n",
    "            # case 4: condition과 gen이 다소 다른 경우 (과도한 알파블렌딩) && ref를 못 맞힌 경우\n",
    "            cnt_list[3] += 1\n",
    "            item_list[3].append(gen_output)\n",
    "\n",
    "print(cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638de05c-c7c9-4325-9ff8-a2c13db54b7b",
   "metadata": {},
   "source": [
    "#### dataset validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da057f-c9cf-4d15-8e3f-99a8e5f6fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "dataset = train_dataset\n",
    "target_str_list = [\n",
    "#     \"주위에 지금 감정을 나눌 수 있는 사람이\",\n",
    "#     \"회사에서 겪는 대인관계\"\n",
    "    \"사람들은 눈에 보여야 인지하는 경향이\"\n",
    "]\n",
    "for row in dataset.raw_data:\n",
    "    utterances = row[\"utterances\"]\n",
    "    concated = \" \".join(utterances)\n",
    "    \n",
    "    flag = True\n",
    "    for target_str in target_str_list:\n",
    "        if target_str not in concated: \n",
    "            flag = False\n",
    "            break\n",
    "    if flag: targets.append(row)\n",
    "print(\"len:\", len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf370f7-ad9b-4e50-9f88-68df7682973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# four_n2x8_one -> epoch_3가 베스트 (2)\n",
    "# selectstar_n2x8_one -> epoch_3가 베스트 (3)\n",
    "# four_n2x8_both -> epoch_7 > 4/5/6가 베스트 (1)\n",
    "# selectstar_n2x8_both -> epoch_4가 베스트 (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3fb9b-cbf4-49de-beb0-0d722d62a7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f59ef-a997-4fe1-bdff-b1c67691d7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T05:19:16.846917Z",
     "start_time": "2021-09-07T05:19:10.534Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_batch = [\"<s>It <mask> retriever. My <mask> cute </s>\", ... ]\n",
    "# decoder_input_batch = [\"</s><s>My dog is cute. It is a golden retriever\", ...]\n",
    "# labels_batch = [\"<s>My dog is cute. It is a golden retriever</s>\", ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfeff9-cef0-4c8c-8baa-5794c23dc2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac5be8a4-28dc-4e34-afad-fa9912a871d4",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7198815-484f-4d4a-a2d3-d488083efceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.services.dialog_generator.bart import BartDialogGenerator\n",
    "generator = BartDialogGenerator()\n",
    "generator.verbose = False\n",
    "_epoch = 6\n",
    "generator.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/bart/v2/condition_bm25/{dataset_name}/epoch_{_epoch}\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "generator.load_model(model_dir=_model_dir)\n",
    "\n",
    "from transformer.services.dialog_retriever.poly_encoder import PolyEncoderDialogRetriever\n",
    "retriever = PolyEncoderDialogRetriever()\n",
    "retriever.verbose = False\n",
    "_epoch = 34\n",
    "retriever.set_device(device=device)\n",
    "_model_dir = dataset_dir + \"/model/poly_encoder/v2/{dataset_name}/epoch_{_epoch}/\".format(dataset_name=dataset_name, _epoch=_epoch)\n",
    "retriever.load_model(model_dir=_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bf429-dc0d-41ce-ac8e-afbbe44a63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.data.utils import simplify_speaker_ids\n",
    "from transformer.utils.common import get_last_index\n",
    "from KoBERTScore import BERTScore\n",
    "from transformer.models.utils import compute_bleu, compute_meteor, compute_rouge, compute_hits, compute_semantic_score\n",
    "\n",
    "def get_metric_inputs(dataset, min_length=1, top_n=10):\n",
    "    for row_idx in range(0, len(dataset.raw_data)):\n",
    "        output = None\n",
    "        \n",
    "        _utterances = dataset.raw_data[row_idx][\"utterances\"]\n",
    "        _speaker_ids = dataset.raw_data[row_idx][\"speaker_ids\"]\n",
    "        _speaker_ids = simplify_speaker_ids(_speaker_ids, user_id=1, model_id=0)\n",
    "        last_index = get_last_index(_speaker_ids, value=1)\n",
    "        utterances = _utterances[:last_index+1]\n",
    "        speaker_ids = _speaker_ids[:last_index+1]\n",
    "        reference = _utterances[last_index+1:]\n",
    "        reference = \" \".join(reference)\n",
    "\n",
    "        try:\n",
    "            context = \" \".join(utterances)\n",
    "            \n",
    "            # non_condition_prediction\n",
    "            outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=None,\n",
    "                                                                 min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                                 beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "            non_condition_prediction = [output[0] for output in outputs][0]\n",
    "            \n",
    "            # condition_prediction\n",
    "            outputs = retriever.infer_next_utterance(utterances=utterances, speaker_ids=speaker_ids,\n",
    "                                       min_length=min_length, top_n=top_n, weight_bm25=False,\n",
    "                                       prev_utterance=None, intersection_tolerance=0.9, max_retry=5)\n",
    "            condition = outputs[0][0]\n",
    "            \n",
    "            outputs = generator.infer_next_utterance_beam_search(utterances=utterances, speaker_ids=speaker_ids, conditions=[condition],\n",
    "                                                                 min_length=min_length, top_n=top_n, repetition_penalty=2.0, no_repeat_ngram_size=3,\n",
    "                                                                 beam_size=10, prev_utterance=None, intersection_tolerance=0.9, max_retry=5, return_probs=True)\n",
    "            condition_prediction = [output[0] for output in outputs][0]\n",
    "\n",
    "            output = {\n",
    "                \"context\": context,\n",
    "                \"reference\": reference,\n",
    "                \"condition\": condition,\n",
    "                \"non_condition_prediction\": non_condition_prediction,\n",
    "                \"condition_prediction\": condition_prediction\n",
    "            }\n",
    "            yield output\n",
    "        except:\n",
    "            yield output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd63a78-350f-4e58-865c-ed73e368fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(model, tokenizer, predictions, references):\n",
    "    scores = dict()\n",
    "    _scores = dict()\n",
    "    if \"bleu\" in metrics:\n",
    "        _scores[\"bleu\"] = compute_bleu(metric=model.metrics[\"bleu\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    if \"meteor\" in metrics:\n",
    "        _scores[\"meteor\"] = compute_meteor(metric=model.metrics[\"meteor\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    if \"rouge\" in metrics:\n",
    "        _scores[\"rouge\"] = compute_rouge(metric=model.metrics[\"rouge\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    if \"semantic_score\" in metrics:\n",
    "        _scores[\"semantic_score\"] = compute_semantic_score(metric=model.metrics[\"semantic_score\"], tokenizer=tokenizer, predictions=predictions, references=references)\n",
    "    \n",
    "    if \"bleu\" in metrics:\n",
    "        _bleu_scores = _scores[\"bleu\"][\"precisions\"]\n",
    "        for ngram in bleu_ngrams:\n",
    "            name = \"BLEU-{n}\".format(n=ngram)\n",
    "            score = _bleu_scores[ngram-1]\n",
    "            score = round(score, 4)\n",
    "            scores[name] = score\n",
    "    if \"meteor\" in metrics:\n",
    "        score = _scores[\"meteor\"][\"meteor\"]\n",
    "        score = round(score, 4)\n",
    "        scores[\"METEOR\"] = score\n",
    "    if \"rouge\" in metrics:\n",
    "        for r in rouge_types:\n",
    "            key = \"rouge{r}\".format(r=r)\n",
    "            if key in _scores[\"rouge\"]:\n",
    "                name = \"ROUGE-{r}\".format(r=r)\n",
    "                score = _scores[\"rouge\"][key]\n",
    "                score = score.mid.fmeasure\n",
    "                score = round(score, 4)\n",
    "                scores[name] = score\n",
    "    if \"hits\" in metrics:\n",
    "        for k, score in zip(hits_k, _scores[\"hits\"]):\n",
    "            name = \"HITS@{k}\".format(k=k)\n",
    "            score = round(score, 4)\n",
    "            scores[name] = score\n",
    "    if \"semantic_score\" in metrics:\n",
    "        name = \"BERTScore\".format(name_or_path=name_or_path)\n",
    "        score = _scores[\"semantic_score\"]\n",
    "        score = round(score, 4)\n",
    "        scores[name] = score\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20b5ac-17e0-412c-babe-f174a0dc83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"bleu\", \"meteor\", \"rouge\", \"semantic_score\"]\n",
    "bleu_ngrams = [3, 4]\n",
    "rouge_types = [\"1\", \"2\", \"L\"]\n",
    "name_or_path = \"beomi/kcbert-base\"\n",
    "decoding_method = \"beam_search\"\n",
    "min_length = 10\n",
    "top_n = 5\n",
    "\n",
    "metric_input_gen = get_metric_inputs(dataset=test_dataset, min_length=min_length, top_n=top_n)\n",
    "\n",
    "non_condition_predictions = []\n",
    "condition_predictions = []\n",
    "references = []\n",
    "for gen_output in tqdm(metric_input_gen):\n",
    "    if gen_output is None: continue\n",
    "    references.append(gen_output[\"reference\"])\n",
    "    non_condition_predictions.append(gen_output[\"non_condition_prediction\"])\n",
    "    condition_predictions.append(gen_output[\"condition_prediction\"])\n",
    "\n",
    "non_condition_scores = compute_scores(model=bart, tokenizer=tokenizer, predictions=non_condition_predictions, references=references)\n",
    "print(\"non_condition_score:\", non_condition_score)\n",
    "\n",
    "condition_scores = compute_scores(model=bart, tokenizer=tokenizer, predictions=condition_predictions, references=references)\n",
    "print(\"condition_scores:\", condition_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
