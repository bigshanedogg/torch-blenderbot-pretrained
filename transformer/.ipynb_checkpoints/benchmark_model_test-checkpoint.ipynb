{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01f00b3cc1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMecabTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpmTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerPreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiheadAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositionwiseFeedForward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformer'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformer.preprocessors.tokenizer import MecabTokenizer, SpmTokenizer\n",
    "from transformer.preprocessors.preprocessor import TransformerPreprocessor\n",
    "from transformer.layers.attention import MultiheadAttention, PositionwiseFeedForward\n",
    "from transformer.layers.embedding import TransformerEmbedding\n",
    "from transformer.layers.transformer import EncoderLayer, DecoderLayer\n",
    "from transformer.layers.utils import get_pad_mask, get_sub_mask\n",
    "from transformer.models.transformer import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/aibud_dev/_jupyter/file_path.json\"\n",
    "file_path = None\n",
    "with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "    file_path = json.load(fp)\n",
    "\n",
    "# # parallel: eng-kor\n",
    "# dataset = None\n",
    "# with open(file_path[\"korean-english-jhe\"][\"pickle\"], \"rb\") as fp:\n",
    "#     dataset = pickle.load(fp)\n",
    "\n",
    "# # conversation: dailydialog dataset\n",
    "# dataset = None\n",
    "# with open(file_path[\"dailydialog\"][\"pickle\"], \"rb\") as fp:\n",
    "#     dataset = pickle.load(fp)\n",
    "\n",
    "# conversation: empatheticdialogues dataset\n",
    "dataset = None\n",
    "with open(file_path[\"empatheticdialogues\"][\"pickle\"], \"rb\") as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "\n",
    "print(\"train: {train}\\tvalid: {valid}\\ttest: {test}\".format(train=len(dataset[\"train\"]), valid=len(dataset[\"valid\"]), test=len(dataset[\"test\"])))\n",
    "\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "valid_df = pd.DataFrame(dataset[\"valid\"])\n",
    "test_df = pd.DataFrame(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture hyperparams\n",
    "src_vocab_size = tgt_vocab_size = 8000\n",
    "src_timesteps = tgt_timesteps = 128\n",
    "num_heads = 8\n",
    "d_model = 768\n",
    "d_ff = 3072\n",
    "dropout = 0.1\n",
    "num_encoder_layer = 6\n",
    "\n",
    "# layer details\n",
    "pwff_activation = \"gelu\"\n",
    "layer_bias = True\n",
    "layer_norm_epsilon = 1e-5\n",
    "layer_initialization = \"normal\"\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_model_path = \"./data/empdial_spm_model_v{vocab_size}\".format(vocab_size=src_vocab_size)\n",
    "\n",
    "# # train spm_model\n",
    "# sentences = train_df[\"utterance\"].unique().tolist()\n",
    "# spm_tokenizer = SpmTokenizer(mlm_ratio=0.15, random_mask_ratio=0.1, skip_mask_ratio=0.1)\n",
    "# spm_tokenizer.train_spm_model(sentences=sentences, vocab_size=vocab_size)\n",
    "# spm_tokenizer.save_spm_model(path=spm_model_path, copy=False)\n",
    "# spm_tokenizer.load_spm_model(path=spm_model_path)\n",
    "\n",
    "prep = TransformerPreprocessor(src_spm_model_path=spm_model_path, tgt_spm_model_path=spm_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = {\"train\":[], \"valid\":[], \"test\":[]}\n",
    "tgt_sentences = {\"train\":[], \"valid\":[], \"test\":[]}\n",
    "\n",
    "for conv_id, group in train_df.groupby([\"conv_id\"]):\n",
    "    utterances = group[\"utterance\"].tolist()\n",
    "    group_length = len(group)\n",
    "    for i in range(0, group_length-1):\n",
    "        src_sentence = utterances[i]\n",
    "        tgt_sentence = utterances[i+1]\n",
    "        src_sentences[\"train\"].append(src_sentence)\n",
    "        tgt_sentences[\"train\"].append(tgt_sentence)\n",
    "        \n",
    "for conv_id, group in valid_df.groupby([\"conv_id\"]):\n",
    "    utterances = group[\"utterance\"].tolist()\n",
    "    group_length = len(group)\n",
    "    for i in range(0, group_length-1):\n",
    "        src_sentence = utterances[i]\n",
    "        tgt_sentence = utterances[i+1]\n",
    "        src_sentences[\"valid\"].append(src_sentence)\n",
    "        tgt_sentences[\"valid\"].append(tgt_sentence)\n",
    "        \n",
    "for conv_id, group in test_df.groupby([\"conv_id\"]):\n",
    "    utterances = group[\"utterance\"].tolist()\n",
    "    group_length = len(group)\n",
    "    for i in range(0, group_length-1):\n",
    "        src_sentence = utterances[i]\n",
    "        tgt_sentence = utterances[i+1]\n",
    "        src_sentences[\"test\"].append(src_sentence)\n",
    "        tgt_sentences[\"test\"].append(tgt_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "src_inputs = np.random.randint(low=0, high=src_vocab_size, size=(batch_size, src_timesteps))\n",
    "tgt_inputs = np.random.randint(low=0, high=tgt_vocab_size, size=(batch_size, tgt_timesteps))\n",
    "src_inputs = torch.from_numpy(src_inputs)\n",
    "tgt_inputs = torch.from_numpy(tgt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_embedding_layer = TransformerEmbedding(timesteps=src_timesteps, d_model=d_model, vocab_size=src_vocab_size)\n",
    "src_embed, src_token_embed_weights = src_embedding_layer(token_ids=src_inputs)\n",
    "src_key_padding_mask = src_inputs==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sub_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "# src_inputs = np.array([\n",
    "#     [1,2,3,4,5,0,0],\n",
    "#     [1,2,3,4,0,0,0],\n",
    "#     [1,2,3,4,0,0,0],\n",
    "#     [1,2,3,4,5,6,7],\n",
    "#     [1,2,3,4,5,6,0],\n",
    "# ])\n",
    "# # src_inputs = np.random.randint(low=0, high=1, size=(batch_size, src_timesteps))\n",
    "# src_inputs = torch.from_numpy(src_inputs)\n",
    "# src_embedding_layer = TransformerEmbedding(timesteps=7, d_model=4, vocab_size=8)\n",
    "# src_embed, src_token_embed_weights = src_embedding_layer(token_ids=src_inputs)\n",
    "# src_key_padding_mask = src_inputs==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = EncoderLayer(d_model=d_model, d_ff=d_ff, num_heads=num_heads, pwff_activation=pwff_activation, dropout=dropout, bias=layer_bias, layer_norm_epsilon=layer_norm_epsilon, initialization=layer_initialization)\n",
    "encoder_layer(src=src_embed, src_key_padding_mask=src_key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder = Encoder(num_encoder_layer=num_encoder_layer, d_model=d_model, d_ff=d_ff, num_heads=num_heads, pwff_activation=pwff_activation, dropout=dropout, bias=layer_bias, layer_norm_epsilon=layer_norm_epsilon, initialization=layer_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder(src=src_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mha_dropout_layer = nn.modules.dropout.Dropout(dropout)\n",
    "self.layer_normalization = nn.modules.normalization.LayerNorm(d_model, eps=layer_norm_epsilon)\n",
    "self.pwff_layer = PositionwiseFeedForward(d_model=d_model, d_ff=d_ff, activation=pwff_activation, dropout=dropout, bias=bias, layer_norm_epsilon=layer_norm_epsilon, initialization=initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, _ = encoder_layer.mha_layer(query=src_embed, key=src_embed, value=src_embed, attn_mask=None, key_padding_mask=src_key_padding_mask)\n",
    "a = a + encoder_layer.mha_dropout_layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = encoder_layer.layer_normalization.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4627,  0.0140,  0.1592,  ...,  1.0100,  0.4225,  0.2227],\n",
       "         [-1.5960, -1.8289, -0.3324,  ..., -0.9353, -0.6446, -3.4256],\n",
       "         [ 0.1701,  2.0713,  1.3529,  ...,  0.0055,  0.3293,  0.4701],\n",
       "         ...,\n",
       "         [ 0.0941, -0.0314,  0.7386,  ...,  0.9152,  0.0209, -1.0458],\n",
       "         [ 0.9894, -0.0057,  0.7685,  ...,  1.5675, -0.6311, -1.1110],\n",
       "         [-1.0514, -2.1482, -1.2280,  ...,  0.3904, -0.4926, -1.0023]],\n",
       "\n",
       "        [[ 0.5447, -0.6459, -0.0889,  ...,  1.8235, -0.7732, -0.3643],\n",
       "         [-0.0459,  1.0868,  1.5638,  ...,  2.1673,  0.5771,  1.9309],\n",
       "         [ 0.2335,  0.2908,  0.3148,  ...,  0.6025,  0.3757,  1.4460],\n",
       "         ...,\n",
       "         [-1.4925, -0.8803,  0.7332,  ...,  0.2888,  0.9605,  1.6413],\n",
       "         [-1.7312, -2.7324, -0.4192,  ..., -0.0670, -1.1935, -2.4884],\n",
       "         [-1.2149, -2.2582, -0.0357,  ...,  0.0203, -0.8691, -0.2761]],\n",
       "\n",
       "        [[ 2.0191,  0.2236,  0.3186,  ...,  0.7660,  1.7304,  0.8944],\n",
       "         [-0.5629, -1.2309,  0.4925,  ..., -0.3275, -0.6958, -1.8255],\n",
       "         [ 0.7736,  1.7301, -0.2851,  ...,  1.8459,  0.8909,  1.4430],\n",
       "         ...,\n",
       "         [ 0.8427,  1.0595,  0.2033,  ..., -0.1481,  0.8002,  0.7410],\n",
       "         [ 0.4435,  0.3189, -0.5750,  ..., -0.0677,  2.0603,  1.1531],\n",
       "         [ 0.4043,  0.2452, -1.9023,  ...,  0.1668,  0.6603,  0.4470]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7414,  0.2063,  0.8145,  ...,  1.9662, -0.3251,  0.3587],\n",
       "         [ 0.1129,  2.3046,  1.2000,  ...,  0.8965, -0.2045,  1.8261],\n",
       "         [ 0.7613,  1.2974,  1.6218,  ...,  1.4121, -0.1084,  0.1811],\n",
       "         ...,\n",
       "         [-2.1981, -0.1521,  0.2678,  ...,  0.7684, -1.1763,  1.5134],\n",
       "         [ 0.0461,  1.4597,  1.5715,  ...,  0.5995,  0.9689,  1.9028],\n",
       "         [-0.7258,  0.6297,  0.7540,  ...,  0.9535,  0.0829,  2.3437]],\n",
       "\n",
       "        [[ 1.0840, -0.5557,  0.5300,  ...,  0.4399, -1.7383,  1.5607],\n",
       "         [ 0.2673, -0.4073,  1.0847,  ...,  0.0968, -0.4290, -0.3832],\n",
       "         [ 1.6682,  1.7710,  0.2216,  ...,  0.4256,  0.2314,  0.8201],\n",
       "         ...,\n",
       "         [ 1.3102, -0.4078,  1.1673,  ...,  0.6207, -1.5457,  0.8466],\n",
       "         [-0.6088, -1.5871, -0.5560,  ..., -1.3252, -1.0879, -0.0273],\n",
       "         [ 2.0294, -0.5458, -0.4849,  ..., -0.2709, -1.4171,  0.0795]],\n",
       "\n",
       "        [[-0.9687,  0.3235, -0.9496,  ..., -0.6462, -1.7151,  0.8257],\n",
       "         [ 0.9795,  2.0607,  0.7481,  ...,  0.4953,  0.6640,  0.0603],\n",
       "         [ 0.6343,  1.3361,  1.4776,  ...,  1.0325,  0.9391,  1.2109],\n",
       "         ...,\n",
       "         [ 1.5210,  0.7699,  1.6601,  ...,  1.0058,  1.4172,  1.2145],\n",
       "         [ 0.0295, -0.7547,  0.4781,  ...,  0.2938, -0.6956,  0.9266],\n",
       "         [-0.2036, -0.7724, -1.1055,  ...,  0.2484, -0.3509,  0.8426]]],\n",
       "       dtype=torch.float64, grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer.layer_normalization(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6a93502023fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_jupyter/pytorch_dev/torch-transformer/transformer/layers/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmha_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmha_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmha_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha_dropout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmha_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmha_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmha_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpwff_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmha_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    171\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2203\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         )\n\u001b[0;32m-> 2205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.4704e-04,  6.0264e-04, -1.7196e-03, -1.3732e-03],\n",
       "          [-1.7554e-04,  4.5347e-04, -1.6458e-03, -1.0186e-03],\n",
       "          [-1.0611e-04,  2.3857e-04, -1.6891e-03, -1.2961e-03],\n",
       "          [-1.3496e-04,  4.2852e-04, -1.9389e-03, -1.5926e-03],\n",
       "          [-1.3442e-04,  4.3101e-04, -1.9348e-03, -1.5910e-03],\n",
       "          [-1.6258e-04,  2.8462e-04, -1.8603e-03, -1.2430e-03],\n",
       "          [-1.3510e-04,  4.2895e-04, -1.9361e-03, -1.5900e-03]],\n",
       " \n",
       "         [[ 1.0305e-05,  1.5170e-03, -1.7464e-03, -2.5096e-03],\n",
       "          [-1.7350e-04,  8.5958e-04, -1.9546e-03, -2.4092e-03],\n",
       "          [ 9.2236e-06,  1.5129e-03, -1.7547e-03, -2.5096e-03],\n",
       "          [ 9.0960e-06,  1.5125e-03, -1.7566e-03, -2.5105e-03],\n",
       "          [ 8.8270e-05,  1.3808e-03, -1.6171e-03, -2.6692e-03],\n",
       "          [ 9.6503e-06,  1.5143e-03, -1.7497e-03, -2.5076e-03],\n",
       "          [ 9.6465e-06,  1.5143e-03, -1.7497e-03, -2.5076e-03]],\n",
       " \n",
       "         [[ 1.0305e-05,  1.5170e-03, -1.7464e-03, -2.5096e-03],\n",
       "          [ 1.5601e-05,  1.2196e-03, -5.3041e-04, -1.8790e-03],\n",
       "          [ 8.7814e-05,  1.3792e-03, -1.6217e-03, -2.6699e-03],\n",
       "          [ 4.1123e-05,  1.5623e-03, -1.5722e-03, -2.0626e-03],\n",
       "          [ 9.6542e-06,  1.5143e-03, -1.7497e-03, -2.5075e-03],\n",
       "          [ 9.6581e-06,  1.5145e-03, -1.7502e-03, -2.5088e-03],\n",
       "          [ 9.6465e-06,  1.5143e-03, -1.7497e-03, -2.5076e-03]],\n",
       " \n",
       "         [[-1.0725e-04, -1.5542e-04, -5.6582e-04, -1.8957e-04],\n",
       "          [-1.1236e-04, -1.1672e-04, -7.0382e-04, -5.7649e-04],\n",
       "          [-1.1201e-04, -1.1586e-04, -7.0399e-04, -5.7728e-04],\n",
       "          [-1.1288e-04, -1.1753e-04, -7.0812e-04, -5.7761e-04],\n",
       "          [-9.8290e-05, -1.3512e-04, -4.7300e-04, -3.7272e-04],\n",
       "          [-6.2476e-05, -3.4599e-04,  9.9651e-05, -2.8844e-04],\n",
       "          [ 2.2485e-06,  3.1085e-04, -6.1611e-04, -7.5016e-04]],\n",
       " \n",
       "         [[-1.2685e-04, -9.3641e-05, -1.1218e-03, -4.2421e-04],\n",
       "          [-1.0269e-04,  6.3991e-05, -1.2639e-03, -9.5434e-04],\n",
       "          [-4.9210e-05,  1.5319e-04, -9.0518e-04, -5.7058e-04],\n",
       "          [-1.0286e-04,  6.3693e-05, -1.2675e-03, -9.5837e-04],\n",
       "          [-9.3136e-05,  2.4110e-05, -1.2920e-03, -1.0130e-03],\n",
       "          [-1.9122e-04, -3.0237e-04, -1.4569e-03, -1.1344e-03],\n",
       "          [-8.1526e-05, -1.3424e-04, -9.7795e-04, -4.5911e-04]]],\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " tensor([[[0.2216, 0.2231, 0.2225, 0.2222, 0.1104, 0.0000, 0.0000],\n",
       "          [0.2224, 0.2219, 0.2221, 0.1111, 0.1113, 0.0000, 0.0000],\n",
       "          [0.2225, 0.1111, 0.2221, 0.1111, 0.2223, 0.0000, 0.0000],\n",
       "          [0.2223, 0.2222, 0.2222, 0.2222, 0.2222, 0.0000, 0.0000],\n",
       "          [0.2220, 0.2225, 0.2224, 0.2222, 0.2220, 0.0000, 0.0000],\n",
       "          [0.2219, 0.2224, 0.2223, 0.1111, 0.2222, 0.0000, 0.0000],\n",
       "          [0.2219, 0.2225, 0.2224, 0.2222, 0.2221, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.2767, 0.2785, 0.2783, 0.2776, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1389, 0.2775, 0.2776, 0.2779, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2781, 0.2775, 0.2777, 0.2778, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2783, 0.2775, 0.2777, 0.2777, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2773, 0.2781, 0.1390, 0.2778, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2774, 0.2780, 0.2778, 0.2780, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2774, 0.2780, 0.2778, 0.2780, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.2767, 0.2785, 0.2783, 0.2776, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.2775, 0.2776, 0.2779, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2781, 0.2775, 0.1388, 0.2778, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2783, 0.2775, 0.2777, 0.1388, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2774, 0.2780, 0.2778, 0.2780, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2773, 0.2781, 0.2779, 0.2778, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2774, 0.2780, 0.2778, 0.2780, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.1581, 0.1586, 0.1588, 0.0794, 0.1582, 0.0795, 0.1596],\n",
       "          [0.1587, 0.1587, 0.1587, 0.1587, 0.1587, 0.1588, 0.1588],\n",
       "          [0.1589, 0.1588, 0.1586, 0.1586, 0.1588, 0.1587, 0.1587],\n",
       "          [0.1590, 0.1588, 0.1587, 0.1587, 0.1588, 0.1587, 0.1584],\n",
       "          [0.1586, 0.1587, 0.1589, 0.1588, 0.1586, 0.0000, 0.1588],\n",
       "          [0.0000, 0.1587, 0.0793, 0.1588, 0.1589, 0.1586, 0.1588],\n",
       "          [0.1592, 0.1588, 0.1587, 0.1589, 0.1593, 0.1582, 0.0790]],\n",
       " \n",
       "         [[0.1845, 0.0927, 0.1857, 0.1851, 0.1846, 0.1856, 0.0000],\n",
       "          [0.1854, 0.1850, 0.1851, 0.1852, 0.1854, 0.1851, 0.0000],\n",
       "          [0.1853, 0.1850, 0.1850, 0.0926, 0.1855, 0.0925, 0.0000],\n",
       "          [0.1855, 0.1850, 0.1851, 0.1851, 0.1853, 0.1851, 0.0000],\n",
       "          [0.1849, 0.1854, 0.0926, 0.1852, 0.1850, 0.1853, 0.0000],\n",
       "          [0.0923, 0.1851, 0.0924, 0.1853, 0.1854, 0.1851, 0.0000],\n",
       "          [0.1849, 0.0000, 0.1852, 0.1853, 0.1852, 0.1852, 0.0000]]],\n",
       "        dtype=torch.float64, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_layer = MultiheadAttention(d_model=4, num_heads=2)\n",
    "mha_layer(query=src_embed, key=src_embed, value=src_embed, key_padding_mask=key_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 7])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 768])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "token_embedding = token_embedding_layer(src_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = TransformerEmbedding(timesteps=src_timesteps, d_model=d_model, vocab_size=src_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEmbedding(\n",
       "  (embed_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (token_embedding_layer): Embedding(8000, 768)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = embedding_layer(token_ids=src_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "         [-0.3894,  0.9744,  0.8984,  ...,  1.6348,  1.1883,  1.1807],\n",
       "         [-0.2898,  1.0740,  0.9980,  ...,  1.7343,  1.2879,  1.2803],\n",
       "         ...,\n",
       "         [-0.7519,  0.6118,  0.5358,  ...,  1.2722,  0.8258,  0.8181],\n",
       "         [-1.6899, -0.3262, -0.4022,  ...,  0.3342, -0.1122, -0.1198],\n",
       "         [-2.2125, -0.8488, -0.9248,  ..., -0.1884, -0.6348, -0.6424]],\n",
       "\n",
       "        [[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "         [-0.3894,  0.9744,  0.8984,  ...,  1.6348,  1.1883,  1.1807],\n",
       "         [-0.2898,  1.0740,  0.9980,  ...,  1.7343,  1.2879,  1.2803],\n",
       "         ...,\n",
       "         [-0.7519,  0.6118,  0.5358,  ...,  1.2722,  0.8258,  0.8181],\n",
       "         [-1.6899, -0.3262, -0.4022,  ...,  0.3342, -0.1122, -0.1198],\n",
       "         [-2.2125, -0.8488, -0.9248,  ..., -0.1884, -0.6348, -0.6424]],\n",
       "\n",
       "        [[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "         [-0.3894,  0.9744,  0.8984,  ...,  1.6348,  1.1883,  1.1807],\n",
       "         [-0.2898,  1.0740,  0.9980,  ...,  1.7343,  1.2879,  1.2803],\n",
       "         ...,\n",
       "         [-0.7519,  0.6118,  0.5358,  ...,  1.2722,  0.8258,  0.8181],\n",
       "         [-1.6899, -0.3262, -0.4022,  ...,  0.3342, -0.1122, -0.1198],\n",
       "         [-2.2125, -0.8488, -0.9248,  ..., -0.1884, -0.6348, -0.6424]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "         [-0.3894,  0.9744,  0.8984,  ...,  1.6348,  1.1883,  1.1807],\n",
       "         [-0.2898,  1.0740,  0.9980,  ...,  1.7343,  1.2879,  1.2803],\n",
       "         ...,\n",
       "         [-0.7519,  0.6118,  0.5358,  ...,  1.2722,  0.8258,  0.8181],\n",
       "         [-1.6899, -0.3262, -0.4022,  ...,  0.3342, -0.1122, -0.1198],\n",
       "         [-2.2125, -0.8488, -0.9248,  ..., -0.1884, -0.6348, -0.6424]],\n",
       "\n",
       "        [[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "         [-0.3894,  0.9744,  0.8984,  ...,  1.6348,  1.1883,  1.1807],\n",
       "         [-0.2898,  1.0740,  0.9980,  ...,  1.7343,  1.2879,  1.2803],\n",
       "         ...,\n",
       "         [-0.7519,  0.6118,  0.5358,  ...,  1.2722,  0.8258,  0.8181],\n",
       "         [-1.6899, -0.3262, -0.4022,  ...,  0.3342, -0.1122, -0.1198],\n",
       "         [-2.2125, -0.8488, -0.9248,  ..., -0.1884, -0.6348, -0.6424]],\n",
       "\n",
       "        [[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "         [-0.3894,  0.9744,  0.8984,  ...,  1.6348,  1.1883,  1.1807],\n",
       "         [-0.2898,  1.0740,  0.9980,  ...,  1.7343,  1.2879,  1.2803],\n",
       "         ...,\n",
       "         [-0.7519,  0.6118,  0.5358,  ...,  1.2722,  0.8258,  0.8181],\n",
       "         [-1.6899, -0.3262, -0.4022,  ...,  0.3342, -0.1122, -0.1198],\n",
       "         [-2.2125, -0.8488, -0.9248,  ..., -0.1884, -0.6348, -0.6424]]],\n",
       "       dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.2178,  0.1460,  0.0700,  ...,  0.8063,  0.3599,  0.3523],\n",
       "        [-0.0388,  1.3134, -0.4791,  ..., -1.5784, -0.7663,  1.0328],\n",
       "        [ 0.6664,  1.1107, -0.7510,  ...,  1.0426, -2.4707,  1.5420],\n",
       "        ...,\n",
       "        [-2.0501, -0.2044, -0.6225,  ...,  0.2221,  2.1806, -0.3275],\n",
       "        [ 0.4914, -1.0143, -1.8016,  ...,  2.1990, -1.0328,  0.2856],\n",
       "        [ 0.8121, -2.6755,  0.6975,  ..., -0.8857,  1.7478,  0.2636]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = Embedding()._position_embed(5, 7)\n",
    "pe = torch.from_numpy(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _position_embed(self, timesteps, d_model):\n",
    "    def _get_angles(timesteps, d_model, i):\n",
    "        default_value = 1e+4\n",
    "        rates = 1 / np.power(default_value, (2 * 1) / np.float32(d_model))\n",
    "        return rates * timesteps\n",
    "\n",
    "    pos_array = np.expand_dims(np.arange(timesteps), axis=1)\n",
    "    i_array = np.expand_dims(np.arange(d_model), axis=0) / 2\n",
    "    pos_embed_matrix = _get_angles(pos_array, d_model, i_array)\n",
    "    pos_embed_matrix[:, 0::2] = np.sin(pos_embed_matrix[:, 0::2])\n",
    "    pos_embed_matrix[:, 1::2] = np.sin(pos_embed_matrix[:, 1::2])\n",
    "    return pos_embed_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HuggingFace Tokneizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", bos_token=\"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'timesteps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-75f89ac906b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrc_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtgt_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'timesteps'"
     ]
    }
   ],
   "source": [
    "src_prep = Preprocessor(timesteps=src_timesteps)\n",
    "tgt_prep = Preprocessor(timesteps=tgt_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"str\" != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported konlpy.tag.Mecab successfully\n",
      "Imported Advanced Mecab successfully\n"
     ]
    }
   ],
   "source": [
    "kor_to_eng_prefix = \"translate Korean to English: \"\n",
    "eng_to_kor_prefix = \"translate English to Korean: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [[13959,  1566,    12,  2968,    10, 11560,  3896,  8881,    19, 3,     9,   748,   349,     3,   390,    16,   368,  1060, 11,  1919]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13959,  1566,    12,  2968,    10, 11560,  3896,  8881,    19,\n",
       "            3,     9,   748,   349,     3,   390,    16,   368,  1060,\n",
       "           11,  1919]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"translate English to German: Hugging Face is a technology company based in New York and Paris\"\n",
    "inputs = tokenizer.encode(sentence, add_special_tokens=False, return_tensors=\"np\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate English to German: Hugging Face is a technology company based in New York and Paris'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13959,  1566,    12,  2968,    10, 11560,  3896,  8881,    19,     3,\n",
       "             9,   748,   349,     3,   390,    16,   368,  1060,    11, 28343,\n",
       "             1]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"translate English to German: Hugging Face is a technology company based in New York and Seoul\"\n",
    "inputs = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate English to German: Hugging Face is a technology company based in New York and Seoul</s>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"translate English to German: Hugging Face is a technology company based in New York and Paris\"\n",
    "inputs = tokenizer.encode(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"translate English to German: Hugging Face is a technology company based in New York and Paris\"\n",
    "inputs = tokenizer.encode(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13959,  1566,    12,  2968,    10, 11560,  3896,  8881,    19,     3,\n",
       "             9,   748,   349,     3,   390,    16,   368,  1060,    11,  1919,\n",
       "             1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = dataset[\"test\"]\n",
    "s = ss[0][\"utterance\"]\n",
    "s\n",
    "\n",
    "masked = prep.src_sentence_encode(sentence=s, language=\"eng\", mask=True)\n",
    "unmasked = prep.src_sentence_encode(sentence=s, language=\"eng\", mask=False)\n",
    "\n",
    "prep.src_decode(rows=[masked, unmasked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict()\n",
    "\n",
    "_type = \"test\"\n",
    "path = file_path[\"empatheticdialogues\"][\"dir\"] + \"{_type}.csv\".format(_type=_type)\n",
    "rows = []\n",
    "_rows = []\n",
    "with open(path, \"r\", encoding=\"UTF-8\") as fp:\n",
    "    for row in fp:\n",
    "        row = row.strip().split(\",\")\n",
    "        if len(row)>=8: \n",
    "            row = row[:8]\n",
    "            rows.append(row)\n",
    "        else:\n",
    "            _rows.append(row)\n",
    "            \n",
    "_dataset = []\n",
    "comma_token = \"_comma_\"\n",
    "headers = rows[0]\n",
    "for _row in rows[1:]:\n",
    "    row = dict()\n",
    "    for header,col in zip(headers,_row):\n",
    "        col = col.replace(comma_token, \",\")\n",
    "        row[header] = col\n",
    "    _dataset.append(row)\n",
    "    \n",
    "print(len(rows), len(_rows))\n",
    "print(len(_dataset))\n",
    "dataset[_type] = _dataset\n",
    "\n",
    "with open(file_path[\"empatheticdialogues\"][\"pickle\"], \"wb\") as fp:\n",
    "    pickle.dump(dataset, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
